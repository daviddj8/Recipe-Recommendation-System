{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b67805f-f09b-4049-8963-0d917b664535",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9059c98f-7ea9-474a-89b1-f50487203dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 11:24:45.742869: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import ast\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, Embedding, Flatten\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d4e0a8-e971-461a-9b23-950e62d3845a",
   "metadata": {},
   "source": [
    "#### Import the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9516255e-23ab-48a6-bad5-c65d92f0084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the saved model\n",
    "model = load_model('../Models/model_binary_crossentropy1.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee33f5ab-2a4c-471d-b583-f708bd56afc4",
   "metadata": {},
   "source": [
    "#### Import the data and prepare the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdfaf4eb-35d3-4768-a591-2db2879828e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the input data\n",
    "merged_df = pd.read_csv('../Data/Preprocessed/NN_Input_Data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2774c584-a316-4e78-a973-5993fd9a49ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>calories</th>\n",
       "      <th>total_fat</th>\n",
       "      <th>sugar</th>\n",
       "      <th>sodium</th>\n",
       "      <th>protein</th>\n",
       "      <th>saturated_fat</th>\n",
       "      <th>carbohydrates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38094</td>\n",
       "      <td>40893</td>\n",
       "      <td>4</td>\n",
       "      <td>495</td>\n",
       "      <td>1533</td>\n",
       "      <td>weeknight time-to-make course main-ingredient ...</td>\n",
       "      <td>4</td>\n",
       "      <td>great northern beans yellow onion diced green ...</td>\n",
       "      <td>9</td>\n",
       "      <td>204.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1293707</td>\n",
       "      <td>40893</td>\n",
       "      <td>5</td>\n",
       "      <td>495</td>\n",
       "      <td>1533</td>\n",
       "      <td>weeknight time-to-make course main-ingredient ...</td>\n",
       "      <td>4</td>\n",
       "      <td>great northern beans yellow onion diced green ...</td>\n",
       "      <td>9</td>\n",
       "      <td>204.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8937</td>\n",
       "      <td>44394</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>56824</td>\n",
       "      <td>30-minutes-or-less time-to-make course main-in...</td>\n",
       "      <td>5</td>\n",
       "      <td>devil's food cake mix vegetable oil eggs reese...</td>\n",
       "      <td>4</td>\n",
       "      <td>132.3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126440</td>\n",
       "      <td>85009</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>64342</td>\n",
       "      <td>15-minutes-or-less time-to-make course main-in...</td>\n",
       "      <td>3</td>\n",
       "      <td>mayonnaise salsa cheddar cheese refried beans ...</td>\n",
       "      <td>13</td>\n",
       "      <td>2786.2</td>\n",
       "      <td>342.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57222</td>\n",
       "      <td>85009</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>64342</td>\n",
       "      <td>15-minutes-or-less time-to-make course main-in...</td>\n",
       "      <td>3</td>\n",
       "      <td>mayonnaise salsa cheddar cheese refried beans ...</td>\n",
       "      <td>13</td>\n",
       "      <td>2786.2</td>\n",
       "      <td>342.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  recipe_id  rating  minutes  contributor_id  \\\n",
       "0    38094      40893       4      495            1533   \n",
       "1  1293707      40893       5      495            1533   \n",
       "2     8937      44394       4       20           56824   \n",
       "3   126440      85009       5       10           64342   \n",
       "4    57222      85009       5       10           64342   \n",
       "\n",
       "                                                tags  n_steps  \\\n",
       "0  weeknight time-to-make course main-ingredient ...        4   \n",
       "1  weeknight time-to-make course main-ingredient ...        4   \n",
       "2  30-minutes-or-less time-to-make course main-in...        5   \n",
       "3  15-minutes-or-less time-to-make course main-in...        3   \n",
       "4  15-minutes-or-less time-to-make course main-in...        3   \n",
       "\n",
       "                                         ingredients  n_ingredients  calories  \\\n",
       "0  great northern beans yellow onion diced green ...              9     204.8   \n",
       "1  great northern beans yellow onion diced green ...              9     204.8   \n",
       "2  devil's food cake mix vegetable oil eggs reese...              4     132.3   \n",
       "3  mayonnaise salsa cheddar cheese refried beans ...             13    2786.2   \n",
       "4  mayonnaise salsa cheddar cheese refried beans ...             13    2786.2   \n",
       "\n",
       "   total_fat  sugar  sodium  protein  saturated_fat  carbohydrates  \n",
       "0        5.0    9.0    26.0     24.0            2.0           10.0  \n",
       "1        5.0    9.0    26.0     24.0            2.0           10.0  \n",
       "2       11.0   39.0     5.0      4.0           11.0            5.0  \n",
       "3      342.0  134.0   290.0    161.0          301.0           42.0  \n",
       "4      342.0  134.0   290.0    161.0          301.0           42.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect df to make sure it imported correctly\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aba9a142-66d9-4795-809b-b548e4aaf56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7209358803285507"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute baseline accuracy needed for improvement.  If we were to predict all recipes would be rated 5, what accuracy would be achieved?\n",
    "np.sum((merged_df['rating'] == 5)) / len(merged_df['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10b4812a-2087-4f9e-86d2-0d7e612f949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate input vs target features\n",
    "X = merged_df[['user_id', 'recipe_id', 'minutes', 'contributor_id', 'tags',\n",
    "       'n_steps', 'ingredients', 'n_ingredients', 'calories', 'total_fat',\n",
    "       'sugar', 'sodium', 'protein', 'saturated_fat', 'carbohydrates']]\n",
    "\n",
    "y = merged_df['rating']\n",
    "\n",
    "# Split the df into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f8e41b5-b3e6-4f43-aeca-446e638b8e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this to create a binary rating column\n",
    "# if 'rating' == 5, then binary will =1, otherwise binary = 0\n",
    "\n",
    "merged_df['binary_rating'] = (merged_df['rating']==5).astype('int')\n",
    "\n",
    "y_binary = merged_df['binary_rating']\n",
    "\n",
    "# Split the df into train and test sets\n",
    "X_train, X_test, y_train_b, y_test_b = train_test_split(X, y_binary, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45e45619-4621-4ad0-b3a7-b31085c27f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure tags and ingredients columns are all strings\n",
    "X_train['tags'] = X_train['tags'].astype(str)\n",
    "X_test['tags'] = X_test['tags'].astype(str)\n",
    "X_train['ingredients'] = X_train['ingredients'].astype(str)\n",
    "X_test['ingredients'] = X_test['ingredients'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60369ca8-bda0-4777-9c04-076f799e61f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's tokenize the tags and ingredients columns\n",
    "\n",
    "# Tokenization for tags\n",
    "tag_tokenizer = Tokenizer()\n",
    "tag_tokenizer.fit_on_texts(X_train['tags'])\n",
    "tag_train_sequences = tag_tokenizer.texts_to_sequences(X_train['tags'])\n",
    "tag_test_sequences = tag_tokenizer.texts_to_sequences(X_test['tags'])\n",
    "\n",
    "# Tokenization for ingredients\n",
    "ingredient_tokenizer = Tokenizer()\n",
    "ingredient_tokenizer.fit_on_texts(X_train['ingredients'])\n",
    "ingredient_train_sequences = ingredient_tokenizer.texts_to_sequences(X_train['ingredients'])\n",
    "ingredient_test_sequences = ingredient_tokenizer.texts_to_sequences(X_test['ingredients'])\n",
    "\n",
    "# Now I'll pad the sequences to ensure uniform input size\n",
    "\n",
    "max_tag_length = max(len(seq) for seq in tag_train_sequences)\n",
    "max_ingredient_length = max(len(seq) for seq in ingredient_train_sequences)\n",
    "\n",
    "tag_train_padded = pad_sequences(tag_train_sequences, maxlen=max_tag_length, padding='post')\n",
    "tag_test_padded = pad_sequences(tag_test_sequences, maxlen=max_tag_length, padding='post')\n",
    "\n",
    "ingredient_train_padded = pad_sequences(ingredient_train_sequences, maxlen=max_ingredient_length, padding='post')\n",
    "ingredient_test_padded = pad_sequences(ingredient_test_sequences, maxlen=max_ingredient_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "274521a7-d1fe-454d-85ac-cfdfb336335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm going to renumber the user_id, recipe_id, and contributor_id starting from 0 to reduce the overhead of the following steps\n",
    "user_id_mapping = {old_id: new_id for new_id, old_id in enumerate(X['user_id'].unique())}\n",
    "X_train['user_id'] = X_train['user_id'].map(user_id_mapping)\n",
    "X_test['user_id'] = X_test['user_id'].map(user_id_mapping)\n",
    "\n",
    "recipe_id_mapping = {old_id: new_id for new_id, old_id in enumerate(X['recipe_id'].unique())}\n",
    "X_train['recipe_id'] = X_train['recipe_id'].map(recipe_id_mapping)\n",
    "X_test['recipe_id'] = X_test['recipe_id'].map(recipe_id_mapping)\n",
    "\n",
    "contributor_id_mapping = {old_id: new_id for new_id, old_id in enumerate(X['contributor_id'].unique())}\n",
    "X_train['contributor_id'] = X_train['contributor_id'].map(contributor_id_mapping)\n",
    "X_test['contributor_id'] = X_test['contributor_id'].map(contributor_id_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7117637a-e6e6-41a3-8a22-817b0e16446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate inputs for user_id, recipe_id, nutrition, and prep\n",
    "X_user_test = X_test['user_id'].values\n",
    "X_recipe_test = X_test['recipe_id'].values\n",
    "X_contributor_test = X_test['contributor_id'].values\n",
    "X_nutrition_test = X_test[['calories', 'total_fat', 'sugar', 'sodium', 'protein', 'saturated_fat', 'carbohydrates']].values\n",
    "X_prep_test = X_test[['n_steps', 'n_ingredients']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a64347-89b3-4a67-82f4-5f38933404c7",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b53b60a4-a740-422f-838d-c7468f629de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10616/10616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7089 - loss: 0.5794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5786146521568298, 0.7097886204719543]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([X_user_test, X_recipe_test, X_contributor_test, X_nutrition_test, X_prep_test, tag_test_padded, ingredient_test_padded], y_test_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10069404-af93-42b8-9ccd-575cfdf83d47",
   "metadata": {},
   "source": [
    "#### Import the other models and evaluate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fff40587-6ec2-40b1-b492-bc59ad8c0ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load_model('../Models/model_crossentropy4.keras')\n",
    "model3 = load_model('../Models/model_crossentropy6.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70405f2e-179b-49ca-a2e5-9689d4354a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10616/10616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.6916 - loss: 0.8968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8947456479072571, 0.6924238801002502]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate([X_user_test, X_recipe_test, X_contributor_test, X_nutrition_test, X_prep_test, tag_test_padded, ingredient_test_padded], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "076f2f42-fd11-4385-b319-ab7f1bc8a729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10616/10616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.6636 - loss: 0.9174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9162075519561768, 0.6645030379295349]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate([X_user_test, X_recipe_test, X_contributor_test, X_prep_test, tag_test_padded, ingredient_test_padded], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392bbe1-0e89-4c52-87fa-6a94cd0d16a3",
   "metadata": {},
   "source": [
    "#### Plot loss and accuracy metrics from each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6082e534-1c43-4183-86b9-381011b5044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the history from each model\n",
    "# crossentropy1_df = pd.read_csv('../Models/Model_Metrics/model_crossentropy1_history.csv', index_col=0)\n",
    "# crossentropy2_df = pd.read_csv('../Models/Model_Metrics/model_crossentropy2_history.csv', index_col=0)\n",
    "# crossentropy3_df = pd.read_csv('../Models/Model_Metrics/model_crossentropy3_history.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87d7c05d-66b6-435d-9be4-2af355679ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Merge into a single df\n",
    "# merged_history = pd.concat([crossentropy1_df, crossentropy2_df, crossentropy3_df], keys = ['model_crossentropy1', 'model_crossentropy2', 'model_crossentropy3'])\n",
    "# merged_history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b9fcf2f-9bc8-4072-bcaa-676093bb0eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.lines as mlines\n",
    "\n",
    "# # Plot accuracy vs. epoch for each model\n",
    "# epochs = [merged_history.index[i][1] + 1 for i in range(0,len(merged_history))]\n",
    "# model = [merged_history.index[i][0] for i in range(0,len(merged_history))]\n",
    "# _ = sns.lineplot(data= merged_history, x = epochs, y = 'accuracy', hue = model)\n",
    "# _ = sns.lineplot(data= merged_history, x = epochs, y = 'val_accuracy', hue = model, linestyle = '--', legend = False)\n",
    "# plt.title('Training and Validation Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "\n",
    "# # Create lines to add to the legend\n",
    "# training_line = mlines.Line2D([], [], color='black', linestyle='-', label='Training')\n",
    "# validation_line = mlines.Line2D([], [], color='black', linestyle='--', label='Validation')\n",
    "\n",
    "# # Add labels to the legend\n",
    "# handles, labels = plt.gca().get_legend_handles_labels()\n",
    "\n",
    "# # Append the custom training and validation handles\n",
    "# handles.extend([training_line, validation_line])\n",
    "# labels.extend(['Training', 'Validation'])\n",
    "# plt.legend(handles = handles, labels = labels)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9d335d9-f48c-493f-836a-712f0976598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot loss function vs. epoch for each model\n",
    "# epochs = [merged_history.index[i][1] + 1 for i in range(0,len(merged_history))]\n",
    "# model = [merged_history.index[i][0] for i in range(0,len(merged_history))]\n",
    "\n",
    "# _ = sns.lineplot(data= merged_history, x = epochs, y = 'loss', hue = model)\n",
    "# _ = sns.lineplot(data= merged_history, x = epochs, y = 'val_loss', hue = model, linestyle = '--', legend = False)\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "\n",
    "# # Create lines to add to the legend\n",
    "# training_line = mlines.Line2D([], [], color='black', linestyle='-', label='Training')\n",
    "# validation_line = mlines.Line2D([], [], color='black', linestyle='--', label='Validation')\n",
    "\n",
    "# # Add labels to the legend\n",
    "# handles, labels = plt.gca().get_legend_handles_labels()\n",
    "\n",
    "# # Append the custom training and validation handles\n",
    "# handles.extend([training_line, validation_line])\n",
    "# labels.extend(['Training', 'Validation'])\n",
    "# plt.legend(handles = handles, labels = labels)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dcd49b-8e06-4733-84ce-160efec32f7c",
   "metadata": {},
   "source": [
    "#### Plot the predicted ratings vs. actual ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "faad2a67-7068-4769-9927-661d9858b822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict([X_user_test, X_recipe_test, X_contributor_test, X_nutrition_test, tag_test_padded, ingredient_test_padded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1465aa83-044b-4e51-90c5-a16a777ad865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_rounded = np.round(y_pred).clip(1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b13398c0-236f-4b46-ae03-ab53a114d7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "# plt.xlabel('True Ratings')\n",
    "# plt.ylabel('Predicted Ratings')\n",
    "# plt.title('True vs. Predicted Ratings')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
